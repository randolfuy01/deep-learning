{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Endangered Animals Image Classification\n",
    "\n"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T18:42:23.251810Z",
     "start_time": "2024-11-21T18:42:18.464540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from PIL import Image\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T18:42:29.430741Z",
     "start_time": "2024-11-21T18:42:29.423640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "if  torch.backends.mps.is_available():\n",
    "    print (\"Using Apple Metal Performance Shaders\")\n",
    "else:\n",
    "    print (\"Using CPU\")\n",
    "\n",
    "torch.set_default_device(device)"
   ],
   "id": "d0c983512403eb80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Using: cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparing Image  & Data\n",
   "id": "f5d13c8fa908b0be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "imsize = 256\n",
    "\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize(size = (imsize, imsize)),  # scale imported image\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)\n",
    "\n"
   ],
   "id": "1c16a8918b1ec667"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Normalization",
   "id": "169f73527d616a65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class Normalization(nn.Module):\n",
    "    sdf\n",
    "\n",
    "\n",
    "def forward(self, img):\n",
    "    sdf"
   ],
   "id": "b472c362c6a59a0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "837c043714a3168b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c65346155876e87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training Function",
   "id": "f2e4871c2cd71596"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    sfsd"
   ],
   "id": "e40580ce908ba7b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
